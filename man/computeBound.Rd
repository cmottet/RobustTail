% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimizationFunctions.R
\name{computeBound}
\alias{computeBound}
\title{computeBound}
\usage{
computeBound(H, mu, sigma, lambda, scale = 1, direction = c("max", "min"))
}
\arguments{
\item{H}{: the function defined in the objective value of program  (5) and (EC.19)}

\item{mu, }{sigma : sorted vectors of length at most 2 containing the lower and upper bound on the first moment in program (EC.19).
If both mu and sigma are scalars, then computeBound solves program (5), otherwise, computeBound solves program (EC.19).}

\item{sigma}{: the second order moment value in program (5)}

\item{lambda}{:  a scalar giving the limit value of the ratio H(x)/x^2 when x goes to infinity}

\item{scale}{: a scalar value by which we scale the optimal objective value. For instance, one can set scale := nu, where
nu is as defined in program (5) and  (EC.19)}

\item{direction}{: a string either "\emph{min}" or "\emph{max}" identifying the type of wether program (5)
should be a min or a max program. Default is "max"}
}
\value{
a list containing the optimal objective value \emph{bound} and distribution function \emph{P} of program  (EC.19) or program (5). In particular, P is a list
 containing point p = (p1, p2) masses and supports points x =(x1,x2).
}
\description{
This function is wrapper to solve either program (5) and (EC.19), in the case
when their feasbile region are restricted to distribution functions with at most two point supports.
}
\examples{
####
#### We wish to solve
####
#### max P(X > c)
#### s.t. sum(p)  = 1
####      sum(px) = 1
####      sum(px^2) = 2
####
#### for some value c. We point out that the solution to this problem is known (see Theorem 3.3 of Bertsimas and Popescu).
#### We can use the function computeBound to solve this problem, which is of the form of program (5).

# Function and parameters for the integral of the objective
H <- function(x) as.numeric(qexp(0.9) <= x)
mu <- 1
sigma <- 2
lambda <- 0

output <- computeBound(H,mu, sigma, lambda)

# Check that the bound matches the analytical solution in Bertsimas
CMsquare <- (sigma- mu^2)/mu^2
delta <-  qexp(0.9)/mu-1

data.frame(Algorithm = output$bound, Analytical = CMsquare/(CMsquare + delta^2))

# Check that the output is feasible
with(output$P, data.frame(moments = c(sum(p),sum(p*x), sum(p*x^2)), truth = c(1,mu,sigma) ))

####
#### The previous problem is also equivalent to
####
#### max P(X > c)
#### s.t. sum(p)  = 1
####      1 <= sum(px) <= 1
####      2 <= sum(px^2) <= 2
####
#### We can use the function computeBound to solve this problem, which is of the form of program (EC.19).
mu <- c(1,1)
sigma <- c(2,2)
lambda <- 0

output <- computeBound(H,mu, sigma, lambda)

# Check that the bound is larger (because we increase the feasible set) than the analytical solution in Bertsimas
data.frame(Algorithm = output$bound, Analytical = CMsquare/(CMsquare + delta^2))

# Check that the output is feasible
with(output$P, data.frame(lowerMomentBound = c(1, mu[1], sigma[1]), moments = c(sum(p),sum(p*x), sum(p*x^2)), upperMomentBound = c(1, mu[2], sigma[2]) ))

#### We now wish to solve
####
#### Max P(x >b)
#### s.t. f(a) = eta
####      f'(a) = -nu
####      1-F(a) = beta
####      f(x) is convex for all x => a
####      f(x) is non-negative for all x => a
####
#### This problem is of the form of program (1). By Theorem 4,  to solve that


a <- qexp(0.7)
eta <- dexp(a)
nu <- dexp(a)
beta <- 1-pexp(a)
mu <- eta/nu
sigma <- 2*beta/nu
lambda <- 1/2
b <- qexp(seq(0.7,0.99, by = 0.01))

runFunc <- function(b){
H <- function(x) 1/2*(x - max(b-a,0) )^2*( max(b-a,0) <= x)
bound <- RobustTail::computeBound(H,mu,sigma,lambda,scale = nu)$bound
output <- data.frame(b = b, bound = bound)
}

dataPlot <- plyr::ldply(parallel::mclapply(X = b, FUN = runFunc, mc.cores = 4))

library(ggplot2)
ggplot(dataPlot, aes(x = b, y = bound)) +
geom_line() +
ylim(c(0,0.3))







}

